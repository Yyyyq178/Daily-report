import arxiv
import google.generativeai as genai
import os
import datetime

# 1. é…ç½® API (ä½¿ç”¨ 2026 æœ€æ–° Gemini 3.0 æ¨¡å‹)
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
FLASH_MODEL = genai.GenerativeModel('gemini-3.0-flash') # ç”¨äºæµ·é‡ç­›é€‰
PRO_MODEL = genai.GenerativeModel('gemini-3.0-pro')    # ç”¨äºæ·±åº¦åˆ†æ

# 2. å®šåˆ¶ä½ çš„ç ”ç©¶å…´è¶£ (æ ¹æ®ä½ çš„ç”»åƒï¼šMAR, å›¾åƒæ¢å¤)
KEYWORDS = [
    # ä½ çš„æ ¸å¿ƒç ”ç©¶æ–¹å‘
    "Image Restoration", "Super-Resolution", "Masked Autoregressive", "MAR",
    
    # çƒ­é—¨ç”Ÿæˆå¼æŠ€æœ¯
    "Diffusion Model", "Generative Adversarial Networks", "Flow-based Model",
    
    # å…³è”çš„é«˜çƒ­åº¦èµ›é“
    "3D Gaussian Splatting", "Segment Anything", "Vision Transformer", 
]
WHITELIST_AUTHORS = ["Kaiming He", "Guangcan Liu"] # ç¤ºä¾‹ï¼šå¯ä»¥æ·»åŠ ä½ å…³æ³¨çš„å¤§ç‰›

def get_latest_papers():
    """è·å–è¿‡å»24å°æ—¶å†… cs.CV çš„è®ºæ–‡"""
    client = arxiv.Client()
    search = arxiv.Search(
        query="cat:cs.CV",
        max_results=50,
        sort_by=arxiv.SortCriterion.SubmittedDate
    )
    return list(client.results(search))

def fast_score(paper):
    """ä½¿ç”¨ 3.0 Flash è¿›è¡Œå¿«é€Ÿæ‰“åˆ† (1-10)"""
    prompt = f"ä½ æ˜¯ä¸€ä¸ªCVä¸“å®¶ã€‚è¯·æ ¹æ®æ ‡é¢˜å’Œæ‘˜è¦ç»™è®ºæ–‡æ‰“åˆ†(1-10)ã€‚é‡ç‚¹å…³æ³¨å›¾åƒæ¢å¤å’Œç”Ÿæˆæ¨¡å‹åˆ›æ–°ã€‚\næ ‡é¢˜ï¼š{paper.title}\næ‘˜è¦ï¼š{paper.summary}"
    try:
        # Flash æ¨¡å‹é€Ÿåº¦æå¿«ä¸”å…è´¹é¢åº¦é«˜
        response = FLASH_MODEL.generate_content(prompt)
        # ç®€å•æå–æ•°å­—é€»è¾‘... (æ­¤å¤„çœç•¥æ­£åˆ™è§£æ)
        return 7 # å‡è®¾è¿”å›åˆ†æ•°
    except:
        return 5

def deep_analyze(paper):
    """ä½¿ç”¨ 3.0 Pro è¿›è¡Œæ·±åº¦åˆ†æ"""
    prompt = f"""
    ä½œä¸ºè®¡ç®—æœºè§†è§‰ä¸“å®¶ï¼Œè¯·æ·±åº¦è§£æè¿™ç¯‡è®ºæ–‡ã€‚
    é‡ç‚¹åˆ†æï¼š1.æ ¸å¿ƒè´¡çŒ® 2.æ–¹æ³•è®ºäº®ç‚¹(Methodology) 3.å¯¹MARæˆ–å›¾åƒæ¢å¤ä»»åŠ¡çš„å¯å‘ã€‚
    ä½¿ç”¨ä¸­æ–‡è¾“å‡ºï¼ŒMarkdownæ ¼å¼ã€‚
    
    æ ‡é¢˜ï¼š{paper.title}
    æ‘˜è¦ï¼š{paper.summary}
    """
    response = PRO_MODEL.generate_content(prompt)
    return response.text

def main():
    papers = get_latest_papers()
    today = datetime.date.today().strftime("%Y-%m-%d")
    report = f"# ğŸš€ CV è®ºæ–‡æ—¥æŠ¥ | {today}\n\n"
    
    high_value_papers = []

    for p in papers:
        # ç²—ç­›ï¼šæ ‡é¢˜å‘½ä¸­å…³é”®è¯
        if any(k.lower() in p.title.lower() for k in KEYWORDS):
            score = fast_score(p)
            if score >= 7:
                high_value_papers.append(p)

    # å¯¹é«˜ä»·å€¼è®ºæ–‡è¿›è¡Œ Pro çº§æ·±åº¦åˆ†æ
    for p in high_value_papers[:5]: # æ¯å¤©ç²¾é€‰å‰5ç¯‡ï¼ŒèŠ‚çœ Pro é¢åº¦
        analysis = deep_analyze(p)
        report += f"## {p.title}\n- **é“¾æ¥**: {p.entry_id}\n\n{analysis}\n\n---\n"

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(report)

if __name__ == "__main__":
    main()
